# Real-Time Traffic Detection Using Semantic Analysis

![Traffic Analysis](traffic-analysis.png)

This is my final year undergrad project, developed from September 2018 to March 2019, leverages semantic analysis on traffic-related tweets to determine the severity of traffic in a particular area, aiding users in making better travel decisions. It incorporates Natural Language Processing (NLP) using Stanford's Core NLP and the Naive Bayes Theorem for classifying tweet streams and notifying traffic presence. Unlike traditional traffic maps that rely on images, this application excels at distinguishing traffic on narrow roads from parked cars, making it a valuable tool for real-time traffic detection.

## Project Structure

The project directory is organized as follows:

- `Lex2.py`: This Python script performs semantic analysis on traffic-related tweets.
- `README.md`: You are reading it right now! This file provides an overview of the project.
- `firstTest.py`: This script likely contains your initial testing or experimentation.
- `multinomial.pkl`: A serialized model or data file used in the analysis.
- `testingData.csv`: Dataset containing test data for evaluating the model.
- `thefile.csv`: An additional dataset or file used in the analysis.
- `thefile2.csv`: Another dataset or file used in the analysis.
- `thefilexyz.csv`: Yet another dataset or file used in the analysis.
- `trainingData.csv`: Dataset containing training data for the machine learning model.
- `try1.py`: A script, possibly representing your project's early attempt or iteration.

## How it Works

1. **Semantic Analysis**: The `Lex2.py` script uses Stanford's Core NLP and the Naive Bayes Theorem to perform semantic analysis on traffic-related tweets.

2. **Data Preparation**: The `trainingData.csv` and `testingData.csv` datasets likely contain labeled data used to train and test your model.

3. **Model Serialization**: The `multinomial.pkl` file appears to contain a serialized model, possibly the result of your machine learning training process.

4. **Traffic Severity Classification**: Using the trained model, the application classifies tweets to determine the severity of traffic, the source of the information, and its reliability.

5. **Real-Time Traffic Updates**: Unlike traditional maps dependent on images, this approach provides real-time traffic updates based on semantic analysis of textual data.

## Usage

To run this project:

1. Ensure you have the required dependencies installed.
2. Run the `Lex2.py` script, providing input data.
3. Observe the severity of traffic and related information generated by the application.

## Contributing

Contributions to enhance this project are welcome! If you'd like to contribute, please follow these steps:

1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Make your changes and commit them.
4. Push your changes to your fork.
5. Create a pull request, detailing the changes you made.
